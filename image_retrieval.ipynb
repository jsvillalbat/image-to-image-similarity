{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1dgoZYGWMAIQ"
      ],
      "authorship_tag": "ABX9TyNG18FJ41CTZH1K9qKw+c2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsvillalbat/image-to-image-similarity/blob/main/image_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto de Busqueda de productos por Fotos TUL\n",
        "En este cuaderno se realiza una prueba de concepto para un buscador de productos por medio de imagenes. La idea es que el usuario tome una imagen de un producto y el usuario recibe imagenes de productos similares que se encuentran en el catalogo de TUL. Este proyecto es basado en este repositorio público de Github [Repositorio Artificio](https://github.com/ankonzoid/artificio/tree/master)"
      ],
      "metadata": {
        "id": "QztY7fTnCmVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar las dependencias y librerias necesarias para el proyecto"
      ],
      "metadata": {
        "id": "TtkfAOGFCiDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import skimage.io\n",
        "from multiprocessing import Pool\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "Cw1IK2XuChvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar imagenes de entrenamiento y test almacenadas de Google Drive"
      ],
      "metadata": {
        "id": "nI3Cx35XAtTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ3zNOk9Aymw",
        "outputId": "5b5b69bc-7664-4464-b393-168e63ef02d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "absolute_path = \"/content/drive/MyDrive/Colab Notebooks/Image Retrieval\"\n",
        "train_dataset_path = absolute_path + \"/train_1\"\n",
        "test_dataset_path = absolute_path + \"/test_1\"\n",
        "output_folder_path = absolute_path + \"/output_1\"\n",
        "# Crear la carpeta donde estarán los resultados si no existe, en Google Drive\n",
        "if not os.path.exists(output_folder_path):\n",
        "    os.makedirs(output_folder_path)"
      ],
      "metadata": {
        "id": "CHggeAc8BSN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones para el cargue de imagenes en memoria"
      ],
      "metadata": {
        "id": "JEQBsvLDYria"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer una imagen\n",
        "def read_img(filePath):\n",
        "    return skimage.io.imread(filePath, as_gray=False)\n",
        "\n",
        "# Leer imagenes con extensiones iguales desde un directorio especifico\n",
        "def read_imgs_dir(dirPath, extensions, parallel=True):\n",
        "    args = [os.path.join(dirPath, filename)\n",
        "            for filename in os.listdir(dirPath)\n",
        "            if any(filename.lower().endswith(ext) for ext in extensions)]\n",
        "    if parallel:\n",
        "        pool = Pool()\n",
        "        imgs = pool.map(read_img, args)\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    else:\n",
        "        imgs = [read_img(arg) for arg in args]\n",
        "    return imgs\n",
        "\n",
        "# Guardar imagen en un archivo\n",
        "def save_img(filePath, img):\n",
        "    skimage.io.imsave(filePath, img)"
      ],
      "metadata": {
        "id": "BvzDNb51YrHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read images\n",
        "extensions = [\".jpg\", \".jpeg\"]\n",
        "print(\"Leyendo imagenes de entrenamiento en: '{}'...\".format(train_dataset_path))\n",
        "imgs_train = read_imgs_dir(train_dataset_path, extensions)\n",
        "print(\"Leyendo imagenes de test en: '{}'...\".format(test_dataset_path))\n",
        "imgs_test = read_imgs_dir(test_dataset_path, extensions)\n",
        "shape_img = imgs_train[0].shape\n",
        "print(\"Tamaño de la imagen = {}\".format(shape_img))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85M8jb0RAs6N",
        "outputId": "adec3d7d-b1c0-4f45-ec62-41eeae68453d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo imagenes de entrenamiento en: '/content/drive/MyDrive/Colab Notebooks/Image Retrieval/train_1'...\n",
            "Leyendo imagenes de test en: '/content/drive/MyDrive/Colab Notebooks/Image Retrieval/test_1'...\n",
            "Tamaño de la imagen = (91, 162, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de imagenes"
      ],
      "metadata": {
        "id": "a1Ym2t0INOdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones para el procesamiento de imagenes, todas las imagenes deben tener el mismo tamaño y tiene que ser normalizadas para un mejor performance del modelo"
      ],
      "metadata": {
        "id": "75jCyiWQAzE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase para realizar la transformacion de las imagenes y ponerlas en el mismo formato\n",
        "class ImageTransformer(object):\n",
        "\n",
        "    def __init__(self, shape_resize):\n",
        "        self.shape_resize = shape_resize\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_transformed = self.resize_img(img, self.shape_resize)\n",
        "        img_transformed = self.normalize_img(img_transformed)\n",
        "        return img_transformed\n",
        "\n",
        "    # Normalize image data [0, 255] -> [0.0, 1.0]\n",
        "    def normalize_img(self, img):\n",
        "        return img / 255.\n",
        "\n",
        "    # Resize de la imagen\n",
        "    def resize_img(self, img, shape_resized):\n",
        "        img_resized = resize(img, shape_resized,\n",
        "                            anti_aliasing=True,\n",
        "                            preserve_range=True)\n",
        "        assert img_resized.shape == shape_resized\n",
        "        return img_resized\n",
        "\n",
        "    # Aplanar imagen\n",
        "    def flatten_img(self, img):\n",
        "        return img.flatten(\"C\")"
      ],
      "metadata": {
        "id": "v7q9sXZ7FXy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apicar las transformaciones a multiples imagenes\n",
        "def apply_transformer(imgs, transformer, parallel=True):\n",
        "    if parallel:\n",
        "        pool = Pool()\n",
        "        imgs_transform = pool.map(transformer, [img for img in imgs])\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    else:\n",
        "        imgs_transform = [transformer(img) for img in imgs]\n",
        "    return imgs_transform"
      ],
      "metadata": {
        "id": "14Lk-kP9F96V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de modelo pre-entrenado"
      ],
      "metadata": {
        "id": "Wce7lD1ANSGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se realiza el proceso de recuperación de imagenes (image retrieval) usando aprendizaje por transferencia sobre un clasificador de imagenes pre-entrenado llamado VGG19 [Documentación Modelo VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/VGG19)"
      ],
      "metadata": {
        "id": "NVKmOxZg-H5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBm5VFO69ydg"
      },
      "outputs": [],
      "source": [
        "# Run mode: (autoencoder -> simpleAE, convAE) or (transfer learning -> vgg19)\n",
        "modelName = \"vgg19\"  # try: \"simpleAE\", \"convAE\", \"vgg19\"\n",
        "trainModel = True\n",
        "parallel = True  # use multicore processing\n",
        "\n",
        "\n",
        "if modelName in [\"vgg19\"]:\n",
        "\n",
        "    # Load pre-trained VGG19 model + higher level layers\n",
        "    print(\"Loading VGG19 pre-trained model...\")\n",
        "    model = tf.keras.applications.VGG19(weights='imagenet', include_top=False,\n",
        "                                        input_shape=shape_img)\n",
        "    model.summary()\n",
        "\n",
        "    shape_img_resize = tuple([int(x) for x in model.input.shape[1:]])\n",
        "    input_shape_model = tuple([int(x) for x in model.input.shape[1:]])\n",
        "    output_shape_model = tuple([int(x) for x in model.output.shape[1:]])\n",
        "    n_epochs = None\n",
        "\n",
        "else:\n",
        "    raise Exception(\"Invalid modelName!\")\n",
        "\n",
        "# Print some model info\n",
        "print(\"input_shape_model = {}\".format(input_shape_model))\n",
        "print(\"output_shape_model = {}\".format(output_shape_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplican las transformaciones necesarias a las imagenes de entrenamiento y test"
      ],
      "metadata": {
        "id": "CGoKXAaLILiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = ImageTransformer(shape_img_resize)\n",
        "print(\"Aplicar transformacion a las imagenes de entrenamiento ...\")\n",
        "imgs_train_transformed = apply_transformer(imgs_train, transformer, parallel=True)\n",
        "print(\"Aplicar transformación a las imagenes de test ...\")\n",
        "imgs_test_transformed = apply_transformer(imgs_test, transformer, parallel=parallel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVsKx7RqIyzs",
        "outputId": "449bb18e-8ec4-40c1-d472-62821985920e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplicar transformacion a las imagenes de entrenamiento ...\n",
            "Aplicar transformación a las imagenes de test ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images to numpy array\n",
        "X_train = np.array(imgs_train_transformed).reshape((-1,) + input_shape_model)\n",
        "X_test = np.array(imgs_test_transformed).reshape((-1,) + input_shape_model)\n",
        "print(\" -> X_train.shape = {}\".format(X_train.shape))\n",
        "print(\" -> X_test.shape = {}\".format(X_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8QNNrcIina",
        "outputId": "a62875d2-2c75-436e-cbb7-2a4bfeb1858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> X_train.shape = (25, 91, 162, 3)\n",
            " -> X_test.shape = (5, 91, 162, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "smdQRbYCJpHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear los embedings de las imagenes de entrenamiento\n",
        "print(\"Inferencia de los embeddings de las imagenes usando el modelo pre-entrenado ...\")\n",
        "E_train = model.predict(X_train)\n",
        "E_train_flatten = E_train.reshape((-1, np.prod(output_shape_model)))\n",
        "E_test = model.predict(X_test)\n",
        "E_test_flatten = E_test.reshape((-1, np.prod(output_shape_model)))\n",
        "print(\" -> E_train.shape = {}\".format(E_train.shape))\n",
        "print(\" -> E_test.shape = {}\".format(E_test.shape))\n",
        "print(\" -> E_train_flatten.shape = {}\".format(E_train_flatten.shape))\n",
        "print(\" -> E_test_flatten.shape = {}\".format(E_test_flatten.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWHqPxBaKdYU",
        "outputId": "ad8921fb-f514-4c3c-d106-262e4129bfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferencia de los embeddings de las imagenes usando el modelo pre-entrenado ...\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 1s 803ms/step\n",
            " -> E_train.shape = (25, 2, 5, 512)\n",
            " -> E_test.shape = (5, 2, 5, 512)\n",
            " -> E_train_flatten.shape = (25, 5120)\n",
            " -> E_test_flatten.shape = (5, 5120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones de utilidad para graficas de resultados"
      ],
      "metadata": {
        "id": "1dgoZYGWMAIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones de utilidad para ver los resultados visualmente, con una imagen del ranking de similitud y una imagen para ver los clusters de imagenes y como se agrupan."
      ],
      "metadata": {
        "id": "BqZkF3skOmtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from sklearn import manifold\n",
        "\n",
        "\n",
        "# Graficar una imagen\n",
        "def plot_img(img, range=[0, 255]):\n",
        "    plt.imshow(img, vmin=range[0], vmax=range[1])\n",
        "    plt.xlabel(\"xpixels\")\n",
        "    plt.ylabel(\"ypixels\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Graficar imagenes en 2 filas: Arriba es la del usuario, y abajo es la respuesta del modelo\n",
        "def plot_query_retrieval(img_query, imgs_retrieval, outFile):\n",
        "    n_retrieval = len(imgs_retrieval)\n",
        "    fig = plt.figure(figsize=(2*n_retrieval, 4))\n",
        "    fig.suptitle(\"Image Retrieval (k={})\".format(n_retrieval), fontsize=25)\n",
        "\n",
        "    # Plot query image\n",
        "    ax = plt.subplot(2, n_retrieval, 0 + 1)\n",
        "    plt.imshow(img_query)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    for axis in ['top', 'bottom', 'left', 'right']:\n",
        "        ax.spines[axis].set_linewidth(4)  # increase border thickness\n",
        "        ax.spines[axis].set_color('black')  # set to black\n",
        "    ax.set_title(\"query\",  fontsize=14)  # set subplot title\n",
        "\n",
        "    # Plot retrieval images\n",
        "    for i, img in enumerate(imgs_retrieval):\n",
        "        ax = plt.subplot(2, n_retrieval, n_retrieval + i + 1)\n",
        "        plt.imshow(img)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        for axis in ['top', 'bottom', 'left', 'right']:\n",
        "            ax.spines[axis].set_linewidth(1)  # set border thickness\n",
        "            ax.spines[axis].set_color('black')  # set to black\n",
        "        ax.set_title(\"Rank #%d\" % (i+1), fontsize=14)  # set subplot title\n",
        "\n",
        "    if outFile is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(outFile, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Grafica de distribución de los vecinos t-SNE\n",
        "def plot_tsne(X, imgs, outFile):\n",
        "\n",
        "    def imscatter(x, y, images, ax=None, zoom=1.0):\n",
        "        if ax is None:\n",
        "            ax = plt.gca()\n",
        "        x, y = np.atleast_1d(x, y)\n",
        "        artists = []\n",
        "        for x0, y0, img0 in zip(x, y, images):\n",
        "            im = OffsetImage(img0, zoom=zoom)\n",
        "            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=True)\n",
        "            artists.append(ax.add_artist(ab))\n",
        "        ax.update_datalim(np.column_stack([x, y]))\n",
        "        ax.autoscale()\n",
        "        return artists\n",
        "\n",
        "    def plot_embedding(X, imgs, title=None):\n",
        "        x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "        X = (X - x_min) / (x_max - x_min)\n",
        "\n",
        "        plt.figure()\n",
        "        ax = plt.subplot(111)\n",
        "        for i in range(X.shape[0]):\n",
        "            plt.text(X[i, 0], X[i, 1], \".\", fontdict={'weight': 'bold', 'size': 9})\n",
        "        if hasattr(offsetbox, 'AnnotationBbox'):\n",
        "            imscatter(X[:,0], X[:,1], imgs, zoom=0.3, ax=ax)\n",
        "\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "        if title is not None:\n",
        "            plt.title(title, fontsize=18)\n",
        "\n",
        "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
        "    X_tsne = tsne.fit_transform(X)\n",
        "    plot_embedding(X_tsne, imgs, \"t-SNE embeddings\")\n",
        "    if outFile is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(outFile, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "WvOiHkZjMEiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluacion con las imagenes de test y traer los 5 vecinos más cercanos"
      ],
      "metadata": {
        "id": "8Rx19UOWM_SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza el algoritmo de vecino más cercano (Nearest Neighbors) para agrupar las imagenes más similares"
      ],
      "metadata": {
        "id": "YfjQBLOkO9Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar modelo kNN sobre las imagenes de entrenamiento\n",
        "print(\"Se hace el fit de un modelo de vecino más cercanos usando las imagenes de entrenamiento ...\")\n",
        "knn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
        "knn.fit(E_train_flatten)\n",
        "\n",
        "\n",
        "# Se realiza la recuperación de las imagenes de test (imagenes tomadas por el usuario)\n",
        "print(\"Realizando la recuperación de las imagenes de test ...\")\n",
        "for i, emb_flatten in enumerate(E_test_flatten):\n",
        "    _, indices = knn.kneighbors([emb_flatten]) # Encontrar los k vecinos mas cercanos en el entrenamiento\n",
        "    img_query = imgs_test[i] # Imagen de test i\n",
        "    imgs_retrieval = [imgs_train[idx] for idx in indices.flatten()] # Imagenes más similares\n",
        "\n",
        "    # Guardar rankeo de imagenes en la carpeta /output\n",
        "    outFile = os.path.join(output_folder_path, \"{}_retrieval_{}.png\".format(modelName, i))\n",
        "    plot_query_retrieval(img_query, imgs_retrieval, outFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSsIckviJ9Hb",
        "outputId": "89aa217e-4e2b-490e-c439-69dc419c6fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se hace el fit de un modelo de vecino más cercanos usando las imagenes de entrenamiento ...\n",
            "Realizando la recuperación de las imagenes de test ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar de la visualización t-SNE (Grafica de vecinos entre los embeddings)\n",
        "print(\"Visualizacion t-SNE sobre las imagenes de entrenamiento ...\")\n",
        "outFile = os.path.join(output_folder_path, \"{}_tsne.png\".format(modelName))\n",
        "plot_tsne(E_train_flatten, imgs_train, outFile)"
      ],
      "metadata": {
        "id": "QCO5vtalL_eV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}